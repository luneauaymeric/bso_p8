{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ee3cfe-8650-4671-8f52-098fc795cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ccc31-25a3-40e5-8843-33aa593842d8",
   "metadata": {},
   "source": [
    "# Récupérer des données de Hal\n",
    "\n",
    "On propose à travers ce notebook de récuperer les métadonnées (doi, pmid, hal-id, auteurs, etc.) des dépôts associés à une collection Hal en utilisant l'api de Hal. Ici, la collection correspond aux publications dont au moins un des auteurs est affilié à un établissement d'enseignement supérieur ou de recherche comme l'Université Paris 8. On peut descendre au niveau d'un laboratoire ou monter au niveau d'une Comue ou d'un EPST.\n",
    "\n",
    "Le nombre de métadonnées peut être allongée ou raccourcie en fonction des besoins. Cela se fait en modifiant la variable `\"fl\"`. \n",
    "\n",
    "En sortie, on récupère des fichiers csv par année de publication, sachant que la requête se fait sur les publication parues entre 2016 et l'année en cours. Chaque fichier est stocké dans `\"./Data/raw/[annee]/\"`, suivant en ce sens la procédure de l'université de Lorraine. Le nom de fichier suit la norme suivante : `hal_<nom-etablissemen>_annee.csv` (exemple : `hal_univ_paris8_annee.csv`).\n",
    "\n",
    "Pour rappel, les url de l'api hal et de sa documentation sont : https://api.archives-ouvertes.fr/search et  https://api.archives-ouvertes.fr/docs/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d88d8ce-584f-4995-b80a-ff78e671f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_universite = \"univ_paris8\" #sert pour le nommage des fichiers\n",
    "struct_hal_Id = 11141 #id de l'université Paris 8\n",
    "\n",
    "url_api_search = \"https://api.archives-ouvertes.fr/search\"\n",
    "\n",
    "params = {\n",
    "    \"q\":f\"structId_i:{struct_hal_Id}\", #la clé de recherche. On peut envisager de faire une recherche sur d'autre champs\n",
    "    \"wt\":\"json\", #Le format de sortie, ici json\n",
    "    \"fl\" : \"halId_s,authFullName_s,authFirstName_s,authLastName_s,authIdHal_s,authIdHal_i,orcidId_s,orcidId_i,doiId_s,pubmedId_s,publicationDateY_i,publicationDate_tdate,openAccess_bool,labStructName_s\", #La liste des champs obtenues\n",
    "    \"sort\" : \"publicationDateY_i asc\", #le champ de tri, ici tri croissant sur l'année\n",
    "    \"rows\" : 10} # le nombre de ligne. Par défaut, l'api affiche les 30 première ligne et le maximum fixé est de 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c051a7-e409-4b15-bb51-2d54d7d6fea3",
   "metadata": {},
   "source": [
    "La cellule ci-dessous permet de définir les paramètres de la requête. On utilise ensuite le module `requests` pour interroger l'api.\n",
    "\n",
    "Les paramètres que nous avons ici définies correspondent à l'url suivante :\n",
    "\n",
    "<a href=\"https://api.archives-ouvertes.fr/search/?q=structId_i:11141&wt=json&fl=label_s,authFullName_s,authIdHal_s,authIdHal_i,orcidId_s,orcidId_i,doiId_s,pubmendId_s&rows=10&sort=publicationDateY_i asc\">https://api.archives-ouvertes.fr/search/?q=structId_i:11141&wt=json&fl=label_s,authFullName_s,authIdHal_s,authIdHal_i,orcidId_s,orcidId_i,doiId_s,pubmendId_s&rows=10&sort=publicationDateY_i asc</a>\n",
    "\n",
    "En cliquant sur lien ou ne le collant dans la barre de recherche de votre navigateur vous verrez les résultats s'afficher. vous pouvez ainsi vérifier au préalable que votre requête fonctionne. Idem, la cellucle ci-dessous permet de vérifier que la fonction `requests.get()` ne retourne pas d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe5af14-e7e6-4299-9dc8-b56f750e528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': {'numFound': 67588, 'start': 0, 'numFoundExact': True, 'docs': [{'openAccess_bool': True, 'authLastName_s': ['Torres-Yepez', 'Gonzalez'], 'authFirstName_s': ['Luis', 'Hugo'], 'authFullName_s': ['Luis Torres-Yepez', 'Hugo Gonzalez'], 'authIdHal_i': [1346255], 'authIdHal_s': ['luis-torres-yepez'], 'labStructName_s': ['Laboratoire Paragraphe'], 'halId_s': 'hal-04713125', 'publicationDate_tdate': '0006-01-01T00:00:00Z', 'publicationDateY_i': 6}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284870', 'publicationDate_tdate': '1956-01-01T00:00:00Z', 'publicationDateY_i': 1956}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284871', 'publicationDate_tdate': '1957-01-01T00:00:00Z', 'publicationDateY_i': 1957}, {'openAccess_bool': True, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284873', 'doiId_s': '10.3406/bagf.1957.7545', 'publicationDate_tdate': '1957-01-01T00:00:00Z', 'publicationDateY_i': 1957}, {'openAccess_bool': True, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284872', 'doiId_s': '10.3406/bagf.1957.7527', 'publicationDate_tdate': '1957-01-01T00:00:00Z', 'publicationDateY_i': 1957}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284874', 'publicationDate_tdate': '1959-01-01T00:00:00Z', 'publicationDateY_i': 1959}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284875', 'publicationDate_tdate': '1960-01-01T00:00:00Z', 'publicationDateY_i': 1960}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284877', 'publicationDate_tdate': '1960-01-01T00:00:00Z', 'publicationDateY_i': 1960}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284876', 'publicationDate_tdate': '1960-01-01T00:00:00Z', 'publicationDateY_i': 1960}, {'openAccess_bool': False, 'authLastName_s': ['Klein'], 'authFirstName_s': ['Claude'], 'authFullName_s': ['Claude Klein'], 'halId_s': 'insu-02284878', 'publicationDate_tdate': '1962-01-01T00:00:00Z', 'publicationDateY_i': 1962}]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    response = requests.get(url_api_search, params)\n",
    "        \n",
    "except HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "except Exception as err:\n",
    "    print(f\"Other error occurred: {err}.\")\n",
    "else:\n",
    "    print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038bd36a-2730-4345-a4d8-1991506c5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_to_csv(response, params, year):\n",
    "    if os.path.exists(f\"./Data/raw/{year}\"):\n",
    "        files = glob.glob(f\"./Data/raw/{year}/hal_*.csv\")\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    # Si le dossier n'existent pas, il est créé\n",
    "    else:\n",
    "        os.makedirs(f\"./Data/raw/{year}\")\n",
    "        \n",
    "    header_csv = params[\"fl\"].split(\",\")\n",
    "    name_file = f\"./Data/raw/{year}/hal_{nom_universite}_{year}.csv\"\n",
    "    \n",
    "    with open(name_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header_csv)\n",
    "        writer.writeheader()\n",
    "\n",
    "    \n",
    "    for x in response['response']['docs']:\n",
    "        row = {}\n",
    "        for column in header_csv:\n",
    "            if column in x.keys():\n",
    "                #print(type(x[column]))\n",
    "                if type(x[column]) is list:\n",
    "                    row[column] = \"|\".join([str(y) for y in x[column]])\n",
    "                else:\n",
    "                    row[column] = x[column]\n",
    "            else:\n",
    "                row[column] = None\n",
    "        with open(name_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=header_csv)\n",
    "            writer.writerow(row)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec619217-7440-4d92-a7f6-e6097fd93faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 3632\n",
      "2017 4131\n",
      "2018 4381\n",
      "2019 4399\n",
      "2020 4051\n",
      "2021 4838\n",
      "2022 5124\n",
      "2023 4434\n",
      "2024 2769\n"
     ]
    }
   ],
   "source": [
    "for x in range(2016,datetime.date.today().year):\n",
    "    params[\"fq\"]= f\"publicationDateY_i:{x}\"\n",
    "    reponse = requests.get(url_api_search, params).json()\n",
    "    print(x, reponse['response']['numFound'])\n",
    "    if reponse['response']['numFound'] <= 10:\n",
    "        params[\"rows\"] = reponse['response']['numFound']\n",
    "        reponse = requests.get(url_api_search, params).json()\n",
    "        list_row = process_json_to_csv(reponse, params, x)\n",
    " \n",
    "        \n",
    "    else:\n",
    "        pages = (int(reponse['response']['numFound']/10000)+1)\n",
    "        for n in range(pages):\n",
    "            params[\"rows\"] = 10000*(n+1)\n",
    "            params[\"start\"] = 10000*n\n",
    "            reponse = requests.get(url_api_search, params).json()\n",
    "            list_row = process_json_to_csv(reponse, params, x)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17421911-6447-4fee-ad39-4dbd0adabc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "for x in glob.glob(f\"./Data/raw/*/hal_*.csv\"):\n",
    "    i+=1\n",
    "    hal_df = pd.read_csv(x, sep=\",\", encoding='utf-8')\n",
    "    \n",
    "    if i== 0:\n",
    "        full_hal = hal_df.copy()\n",
    "    else:\n",
    "        full_hal = pd.concat([full_hal,hal_df])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5a8571-9e6f-4b07-b41b-a73bf711b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hal.to_csv(\"./Data/outputs/202500610_hal_univ_paris8.csv\", sep =\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954295f-608d-4498-a503-68cf71e6920d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bso",
   "language": "python",
   "name": "bso"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
